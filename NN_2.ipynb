{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1190</th>\n",
       "      <th>f_1191</th>\n",
       "      <th>f_1192</th>\n",
       "      <th>f_1193</th>\n",
       "      <th>f_1194</th>\n",
       "      <th>f_1195</th>\n",
       "      <th>f_1196</th>\n",
       "      <th>f_1197</th>\n",
       "      <th>f_1198</th>\n",
       "      <th>f_1199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.033875</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>-0.142131</td>\n",
       "      <td>-0.177117</td>\n",
       "      <td>-1.470684</td>\n",
       "      <td>1.669562</td>\n",
       "      <td>-0.196530</td>\n",
       "      <td>-0.125239</td>\n",
       "      <td>-0.452284</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.111266</td>\n",
       "      <td>0.716084</td>\n",
       "      <td>0.060039</td>\n",
       "      <td>0.301279</td>\n",
       "      <td>-1.174846</td>\n",
       "      <td>-1.076498</td>\n",
       "      <td>-0.069452</td>\n",
       "      <td>-0.604012</td>\n",
       "      <td>-2.179176</td>\n",
       "      <td>0.558003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.348835</td>\n",
       "      <td>0.294815</td>\n",
       "      <td>-0.557577</td>\n",
       "      <td>-2.020773</td>\n",
       "      <td>-1.234715</td>\n",
       "      <td>1.633930</td>\n",
       "      <td>-1.680658</td>\n",
       "      <td>-0.358146</td>\n",
       "      <td>0.166122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735240</td>\n",
       "      <td>0.829781</td>\n",
       "      <td>1.521941</td>\n",
       "      <td>1.347946</td>\n",
       "      <td>0.754505</td>\n",
       "      <td>1.330642</td>\n",
       "      <td>-0.754453</td>\n",
       "      <td>0.582956</td>\n",
       "      <td>0.252671</td>\n",
       "      <td>1.495870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.113248</td>\n",
       "      <td>-0.607726</td>\n",
       "      <td>-0.947791</td>\n",
       "      <td>0.830851</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.498321</td>\n",
       "      <td>-1.493958</td>\n",
       "      <td>0.789572</td>\n",
       "      <td>-1.311018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104698</td>\n",
       "      <td>0.616189</td>\n",
       "      <td>-1.035953</td>\n",
       "      <td>2.111387</td>\n",
       "      <td>-0.984415</td>\n",
       "      <td>1.148076</td>\n",
       "      <td>-1.433554</td>\n",
       "      <td>0.243372</td>\n",
       "      <td>0.170083</td>\n",
       "      <td>1.274795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.223321</td>\n",
       "      <td>-0.479048</td>\n",
       "      <td>-1.925789</td>\n",
       "      <td>1.680377</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>-1.453307</td>\n",
       "      <td>0.605559</td>\n",
       "      <td>-0.019024</td>\n",
       "      <td>1.065448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360237</td>\n",
       "      <td>-1.957863</td>\n",
       "      <td>-0.123384</td>\n",
       "      <td>1.505329</td>\n",
       "      <td>0.660290</td>\n",
       "      <td>-1.769443</td>\n",
       "      <td>-0.547756</td>\n",
       "      <td>-0.568122</td>\n",
       "      <td>0.244645</td>\n",
       "      <td>0.982116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.160109</td>\n",
       "      <td>0.422684</td>\n",
       "      <td>-0.308029</td>\n",
       "      <td>0.227744</td>\n",
       "      <td>0.432854</td>\n",
       "      <td>0.608348</td>\n",
       "      <td>0.193832</td>\n",
       "      <td>1.035091</td>\n",
       "      <td>-0.538868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416629</td>\n",
       "      <td>1.441766</td>\n",
       "      <td>0.212572</td>\n",
       "      <td>-0.994721</td>\n",
       "      <td>1.143999</td>\n",
       "      <td>-2.166923</td>\n",
       "      <td>-1.199248</td>\n",
       "      <td>-1.028636</td>\n",
       "      <td>0.752791</td>\n",
       "      <td>0.317169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels       f_0       f_1       f_2       f_3       f_4       f_5   \n",
       "0       0 -2.033875  0.978446 -0.142131 -0.177117 -1.470684  1.669562  \\\n",
       "1       1 -0.348835  0.294815 -0.557577 -2.020773 -1.234715  1.633930   \n",
       "2       1  0.113248 -0.607726 -0.947791  0.830851  0.998291  0.498321   \n",
       "3       0  1.223321 -0.479048 -1.925789  1.680377  0.021840 -1.453307   \n",
       "4       0  0.160109  0.422684 -0.308029  0.227744  0.432854  0.608348   \n",
       "\n",
       "        f_6       f_7       f_8  ...    f_1190    f_1191    f_1192    f_1193   \n",
       "0 -0.196530 -0.125239 -0.452284  ... -1.111266  0.716084  0.060039  0.301279  \\\n",
       "1 -1.680658 -0.358146  0.166122  ...  0.735240  0.829781  1.521941  1.347946   \n",
       "2 -1.493958  0.789572 -1.311018  ...  0.104698  0.616189 -1.035953  2.111387   \n",
       "3  0.605559 -0.019024  1.065448  ...  0.360237 -1.957863 -0.123384  1.505329   \n",
       "4  0.193832  1.035091 -0.538868  ...  0.416629  1.441766  0.212572 -0.994721   \n",
       "\n",
       "     f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
       "0 -1.174846 -1.076498 -0.069452 -0.604012 -2.179176  0.558003  \n",
       "1  0.754505  1.330642 -0.754453  0.582956  0.252671  1.495870  \n",
       "2 -0.984415  1.148076 -1.433554  0.243372  0.170083  1.274795  \n",
       "3  0.660290 -1.769443 -0.547756 -0.568122  0.244645  0.982116  \n",
       "4  1.143999 -2.166923 -1.199248 -1.028636  0.752791  0.317169  \n",
       "\n",
       "[5 rows x 1201 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in (data.isnull().sum()):\n",
    "    if x != 0:\n",
    "        print(\"Null found at \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1190</th>\n",
       "      <th>f_1191</th>\n",
       "      <th>f_1192</th>\n",
       "      <th>f_1193</th>\n",
       "      <th>f_1194</th>\n",
       "      <th>f_1195</th>\n",
       "      <th>f_1196</th>\n",
       "      <th>f_1197</th>\n",
       "      <th>f_1198</th>\n",
       "      <th>f_1199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.603023</td>\n",
       "      <td>-2.604266</td>\n",
       "      <td>0.991972</td>\n",
       "      <td>-0.473765</td>\n",
       "      <td>-0.605116</td>\n",
       "      <td>-1.614553</td>\n",
       "      <td>1.671046</td>\n",
       "      <td>-0.022425</td>\n",
       "      <td>-0.055823</td>\n",
       "      <td>-0.325416</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.624559</td>\n",
       "      <td>1.063572</td>\n",
       "      <td>-0.032807</td>\n",
       "      <td>0.583405</td>\n",
       "      <td>-0.999795</td>\n",
       "      <td>-0.902615</td>\n",
       "      <td>0.029085</td>\n",
       "      <td>-1.033815</td>\n",
       "      <td>-2.009790</td>\n",
       "      <td>0.614850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.658312</td>\n",
       "      <td>-0.790418</td>\n",
       "      <td>0.231447</td>\n",
       "      <td>-0.902375</td>\n",
       "      <td>-2.536834</td>\n",
       "      <td>-1.370918</td>\n",
       "      <td>1.631245</td>\n",
       "      <td>-1.504373</td>\n",
       "      <td>-0.312871</td>\n",
       "      <td>0.310758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337170</td>\n",
       "      <td>1.171431</td>\n",
       "      <td>1.491790</td>\n",
       "      <td>1.640938</td>\n",
       "      <td>0.851902</td>\n",
       "      <td>1.458978</td>\n",
       "      <td>-0.720660</td>\n",
       "      <td>0.223115</td>\n",
       "      <td>0.488134</td>\n",
       "      <td>1.660502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.658312</td>\n",
       "      <td>-0.293013</td>\n",
       "      <td>-0.772610</td>\n",
       "      <td>-1.304954</td>\n",
       "      <td>0.450997</td>\n",
       "      <td>0.934638</td>\n",
       "      <td>0.362784</td>\n",
       "      <td>-1.317948</td>\n",
       "      <td>0.953811</td>\n",
       "      <td>-1.208823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332718</td>\n",
       "      <td>0.968807</td>\n",
       "      <td>-1.175800</td>\n",
       "      <td>2.412305</td>\n",
       "      <td>-0.817028</td>\n",
       "      <td>1.279866</td>\n",
       "      <td>-1.463948</td>\n",
       "      <td>-0.136485</td>\n",
       "      <td>0.403303</td>\n",
       "      <td>1.414020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.603023</td>\n",
       "      <td>0.901916</td>\n",
       "      <td>-0.629459</td>\n",
       "      <td>-2.313940</td>\n",
       "      <td>1.341100</td>\n",
       "      <td>-0.073537</td>\n",
       "      <td>-1.817159</td>\n",
       "      <td>0.778487</td>\n",
       "      <td>0.061402</td>\n",
       "      <td>1.235924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061234</td>\n",
       "      <td>-1.473064</td>\n",
       "      <td>-0.224096</td>\n",
       "      <td>1.799955</td>\n",
       "      <td>0.761479</td>\n",
       "      <td>-1.582447</td>\n",
       "      <td>-0.494427</td>\n",
       "      <td>-0.995809</td>\n",
       "      <td>0.479890</td>\n",
       "      <td>1.087704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.603023</td>\n",
       "      <td>-0.242570</td>\n",
       "      <td>0.373698</td>\n",
       "      <td>-0.644921</td>\n",
       "      <td>-0.180917</td>\n",
       "      <td>0.350830</td>\n",
       "      <td>0.485683</td>\n",
       "      <td>0.367364</td>\n",
       "      <td>1.224779</td>\n",
       "      <td>-0.414487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001323</td>\n",
       "      <td>1.751990</td>\n",
       "      <td>0.126268</td>\n",
       "      <td>-0.726049</td>\n",
       "      <td>1.225719</td>\n",
       "      <td>-1.972406</td>\n",
       "      <td>-1.207496</td>\n",
       "      <td>-1.483468</td>\n",
       "      <td>1.001844</td>\n",
       "      <td>0.346338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels       f_0       f_1       f_2       f_3       f_4       f_5   \n",
       "0 -0.603023 -2.604266  0.991972 -0.473765 -0.605116 -1.614553  1.671046  \\\n",
       "1  1.658312 -0.790418  0.231447 -0.902375 -2.536834 -1.370918  1.631245   \n",
       "2  1.658312 -0.293013 -0.772610 -1.304954  0.450997  0.934638  0.362784   \n",
       "3 -0.603023  0.901916 -0.629459 -2.313940  1.341100 -0.073537 -1.817159   \n",
       "4 -0.603023 -0.242570  0.373698 -0.644921 -0.180917  0.350830  0.485683   \n",
       "\n",
       "        f_6       f_7       f_8  ...    f_1190    f_1191    f_1192    f_1193   \n",
       "0 -0.022425 -0.055823 -0.325416  ... -1.624559  1.063572 -0.032807  0.583405  \\\n",
       "1 -1.504373 -0.312871  0.310758  ...  0.337170  1.171431  1.491790  1.640938   \n",
       "2 -1.317948  0.953811 -1.208823  ... -0.332718  0.968807 -1.175800  2.412305   \n",
       "3  0.778487  0.061402  1.235924  ... -0.061234 -1.473064 -0.224096  1.799955   \n",
       "4  0.367364  1.224779 -0.414487  ... -0.001323  1.751990  0.126268 -0.726049   \n",
       "\n",
       "     f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
       "0 -0.999795 -0.902615  0.029085 -1.033815 -2.009790  0.614850  \n",
       "1  0.851902  1.458978 -0.720660  0.223115  0.488134  1.660502  \n",
       "2 -0.817028  1.279866 -1.463948 -0.136485  0.403303  1.414020  \n",
       "3  0.761479 -1.582447 -0.494427 -0.995809  0.479890  1.087704  \n",
       "4  1.225719 -1.972406 -1.207496 -1.483468  1.001844  0.346338  \n",
       "\n",
       "[5 rows x 1201 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['labels']\n",
    "x = df_scaled.drop(columns=['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 1200)\n",
      "(4200,)\n",
      "(1050, 1200)\n",
      "(1050,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state= 42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "model_tune = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),input_shape=[None]),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(momentum=0.9)\n",
    "\n",
    "model_tune.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer)\n",
    "\n",
    "history = model_tune.fit(x_train, y_train, epochs=50, callbacks=[lr_schedule])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        if logs.get('val_accuracy') is not None and logs.get('val_accuracy') >= 0.98:                 \n",
    "            print(\"\\nReached 88% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = myCallback()\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(10024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(5024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "        tf.keras.layers.Dropout(0.35),\n",
    "        tf.keras.layers.Dense(504, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "                loss= \"binary_crossentropy\", \n",
    "                metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 70, callbacks=[callbacks], validation_data= (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history[\"val_{}\".format(metric)])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, f'val_{metric}'])\n",
    "    plt.show()\n",
    "    \n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
