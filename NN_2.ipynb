{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1190</th>\n",
       "      <th>f_1191</th>\n",
       "      <th>f_1192</th>\n",
       "      <th>f_1193</th>\n",
       "      <th>f_1194</th>\n",
       "      <th>f_1195</th>\n",
       "      <th>f_1196</th>\n",
       "      <th>f_1197</th>\n",
       "      <th>f_1198</th>\n",
       "      <th>f_1199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.033875</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>-0.142131</td>\n",
       "      <td>-0.177117</td>\n",
       "      <td>-1.470684</td>\n",
       "      <td>1.669562</td>\n",
       "      <td>-0.196530</td>\n",
       "      <td>-0.125239</td>\n",
       "      <td>-0.452284</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.111266</td>\n",
       "      <td>0.716084</td>\n",
       "      <td>0.060039</td>\n",
       "      <td>0.301279</td>\n",
       "      <td>-1.174846</td>\n",
       "      <td>-1.076498</td>\n",
       "      <td>-0.069452</td>\n",
       "      <td>-0.604012</td>\n",
       "      <td>-2.179176</td>\n",
       "      <td>0.558003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.348835</td>\n",
       "      <td>0.294815</td>\n",
       "      <td>-0.557577</td>\n",
       "      <td>-2.020773</td>\n",
       "      <td>-1.234715</td>\n",
       "      <td>1.633930</td>\n",
       "      <td>-1.680658</td>\n",
       "      <td>-0.358146</td>\n",
       "      <td>0.166122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735240</td>\n",
       "      <td>0.829781</td>\n",
       "      <td>1.521941</td>\n",
       "      <td>1.347946</td>\n",
       "      <td>0.754505</td>\n",
       "      <td>1.330642</td>\n",
       "      <td>-0.754453</td>\n",
       "      <td>0.582956</td>\n",
       "      <td>0.252671</td>\n",
       "      <td>1.495870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.113248</td>\n",
       "      <td>-0.607726</td>\n",
       "      <td>-0.947791</td>\n",
       "      <td>0.830851</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.498321</td>\n",
       "      <td>-1.493958</td>\n",
       "      <td>0.789572</td>\n",
       "      <td>-1.311018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104698</td>\n",
       "      <td>0.616189</td>\n",
       "      <td>-1.035953</td>\n",
       "      <td>2.111387</td>\n",
       "      <td>-0.984415</td>\n",
       "      <td>1.148076</td>\n",
       "      <td>-1.433554</td>\n",
       "      <td>0.243372</td>\n",
       "      <td>0.170083</td>\n",
       "      <td>1.274795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.223321</td>\n",
       "      <td>-0.479048</td>\n",
       "      <td>-1.925789</td>\n",
       "      <td>1.680377</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>-1.453307</td>\n",
       "      <td>0.605559</td>\n",
       "      <td>-0.019024</td>\n",
       "      <td>1.065448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360237</td>\n",
       "      <td>-1.957863</td>\n",
       "      <td>-0.123384</td>\n",
       "      <td>1.505329</td>\n",
       "      <td>0.660290</td>\n",
       "      <td>-1.769443</td>\n",
       "      <td>-0.547756</td>\n",
       "      <td>-0.568122</td>\n",
       "      <td>0.244645</td>\n",
       "      <td>0.982116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.160109</td>\n",
       "      <td>0.422684</td>\n",
       "      <td>-0.308029</td>\n",
       "      <td>0.227744</td>\n",
       "      <td>0.432854</td>\n",
       "      <td>0.608348</td>\n",
       "      <td>0.193832</td>\n",
       "      <td>1.035091</td>\n",
       "      <td>-0.538868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416629</td>\n",
       "      <td>1.441766</td>\n",
       "      <td>0.212572</td>\n",
       "      <td>-0.994721</td>\n",
       "      <td>1.143999</td>\n",
       "      <td>-2.166923</td>\n",
       "      <td>-1.199248</td>\n",
       "      <td>-1.028636</td>\n",
       "      <td>0.752791</td>\n",
       "      <td>0.317169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels       f_0       f_1       f_2       f_3       f_4       f_5   \n",
       "0       0 -2.033875  0.978446 -0.142131 -0.177117 -1.470684  1.669562  \\\n",
       "1       1 -0.348835  0.294815 -0.557577 -2.020773 -1.234715  1.633930   \n",
       "2       1  0.113248 -0.607726 -0.947791  0.830851  0.998291  0.498321   \n",
       "3       0  1.223321 -0.479048 -1.925789  1.680377  0.021840 -1.453307   \n",
       "4       0  0.160109  0.422684 -0.308029  0.227744  0.432854  0.608348   \n",
       "\n",
       "        f_6       f_7       f_8  ...    f_1190    f_1191    f_1192    f_1193   \n",
       "0 -0.196530 -0.125239 -0.452284  ... -1.111266  0.716084  0.060039  0.301279  \\\n",
       "1 -1.680658 -0.358146  0.166122  ...  0.735240  0.829781  1.521941  1.347946   \n",
       "2 -1.493958  0.789572 -1.311018  ...  0.104698  0.616189 -1.035953  2.111387   \n",
       "3  0.605559 -0.019024  1.065448  ...  0.360237 -1.957863 -0.123384  1.505329   \n",
       "4  0.193832  1.035091 -0.538868  ...  0.416629  1.441766  0.212572 -0.994721   \n",
       "\n",
       "     f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
       "0 -1.174846 -1.076498 -0.069452 -0.604012 -2.179176  0.558003  \n",
       "1  0.754505  1.330642 -0.754453  0.582956  0.252671  1.495870  \n",
       "2 -0.984415  1.148076 -1.433554  0.243372  0.170083  1.274795  \n",
       "3  0.660290 -1.769443 -0.547756 -0.568122  0.244645  0.982116  \n",
       "4  1.143999 -2.166923 -1.199248 -1.028636  0.752791  0.317169  \n",
       "\n",
       "[5 rows x 1201 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in (data.isnull().sum()):\n",
    "    if x != 0:\n",
    "        print(\"Null found at \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1190</th>\n",
       "      <th>f_1191</th>\n",
       "      <th>f_1192</th>\n",
       "      <th>f_1193</th>\n",
       "      <th>f_1194</th>\n",
       "      <th>f_1195</th>\n",
       "      <th>f_1196</th>\n",
       "      <th>f_1197</th>\n",
       "      <th>f_1198</th>\n",
       "      <th>f_1199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.603023</td>\n",
       "      <td>-2.604266</td>\n",
       "      <td>0.991972</td>\n",
       "      <td>-0.473765</td>\n",
       "      <td>-0.605116</td>\n",
       "      <td>-1.614553</td>\n",
       "      <td>1.671046</td>\n",
       "      <td>-0.022425</td>\n",
       "      <td>-0.055823</td>\n",
       "      <td>-0.325416</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.624559</td>\n",
       "      <td>1.063572</td>\n",
       "      <td>-0.032807</td>\n",
       "      <td>0.583405</td>\n",
       "      <td>-0.999795</td>\n",
       "      <td>-0.902615</td>\n",
       "      <td>0.029085</td>\n",
       "      <td>-1.033815</td>\n",
       "      <td>-2.009790</td>\n",
       "      <td>0.614850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.658312</td>\n",
       "      <td>-0.790418</td>\n",
       "      <td>0.231447</td>\n",
       "      <td>-0.902375</td>\n",
       "      <td>-2.536834</td>\n",
       "      <td>-1.370918</td>\n",
       "      <td>1.631245</td>\n",
       "      <td>-1.504373</td>\n",
       "      <td>-0.312871</td>\n",
       "      <td>0.310758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337170</td>\n",
       "      <td>1.171431</td>\n",
       "      <td>1.491790</td>\n",
       "      <td>1.640938</td>\n",
       "      <td>0.851902</td>\n",
       "      <td>1.458978</td>\n",
       "      <td>-0.720660</td>\n",
       "      <td>0.223115</td>\n",
       "      <td>0.488134</td>\n",
       "      <td>1.660502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.658312</td>\n",
       "      <td>-0.293013</td>\n",
       "      <td>-0.772610</td>\n",
       "      <td>-1.304954</td>\n",
       "      <td>0.450997</td>\n",
       "      <td>0.934638</td>\n",
       "      <td>0.362784</td>\n",
       "      <td>-1.317948</td>\n",
       "      <td>0.953811</td>\n",
       "      <td>-1.208823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332718</td>\n",
       "      <td>0.968807</td>\n",
       "      <td>-1.175800</td>\n",
       "      <td>2.412305</td>\n",
       "      <td>-0.817028</td>\n",
       "      <td>1.279866</td>\n",
       "      <td>-1.463948</td>\n",
       "      <td>-0.136485</td>\n",
       "      <td>0.403303</td>\n",
       "      <td>1.414020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.603023</td>\n",
       "      <td>0.901916</td>\n",
       "      <td>-0.629459</td>\n",
       "      <td>-2.313940</td>\n",
       "      <td>1.341100</td>\n",
       "      <td>-0.073537</td>\n",
       "      <td>-1.817159</td>\n",
       "      <td>0.778487</td>\n",
       "      <td>0.061402</td>\n",
       "      <td>1.235924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061234</td>\n",
       "      <td>-1.473064</td>\n",
       "      <td>-0.224096</td>\n",
       "      <td>1.799955</td>\n",
       "      <td>0.761479</td>\n",
       "      <td>-1.582447</td>\n",
       "      <td>-0.494427</td>\n",
       "      <td>-0.995809</td>\n",
       "      <td>0.479890</td>\n",
       "      <td>1.087704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.603023</td>\n",
       "      <td>-0.242570</td>\n",
       "      <td>0.373698</td>\n",
       "      <td>-0.644921</td>\n",
       "      <td>-0.180917</td>\n",
       "      <td>0.350830</td>\n",
       "      <td>0.485683</td>\n",
       "      <td>0.367364</td>\n",
       "      <td>1.224779</td>\n",
       "      <td>-0.414487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001323</td>\n",
       "      <td>1.751990</td>\n",
       "      <td>0.126268</td>\n",
       "      <td>-0.726049</td>\n",
       "      <td>1.225719</td>\n",
       "      <td>-1.972406</td>\n",
       "      <td>-1.207496</td>\n",
       "      <td>-1.483468</td>\n",
       "      <td>1.001844</td>\n",
       "      <td>0.346338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels       f_0       f_1       f_2       f_3       f_4       f_5   \n",
       "0 -0.603023 -2.604266  0.991972 -0.473765 -0.605116 -1.614553  1.671046  \\\n",
       "1  1.658312 -0.790418  0.231447 -0.902375 -2.536834 -1.370918  1.631245   \n",
       "2  1.658312 -0.293013 -0.772610 -1.304954  0.450997  0.934638  0.362784   \n",
       "3 -0.603023  0.901916 -0.629459 -2.313940  1.341100 -0.073537 -1.817159   \n",
       "4 -0.603023 -0.242570  0.373698 -0.644921 -0.180917  0.350830  0.485683   \n",
       "\n",
       "        f_6       f_7       f_8  ...    f_1190    f_1191    f_1192    f_1193   \n",
       "0 -0.022425 -0.055823 -0.325416  ... -1.624559  1.063572 -0.032807  0.583405  \\\n",
       "1 -1.504373 -0.312871  0.310758  ...  0.337170  1.171431  1.491790  1.640938   \n",
       "2 -1.317948  0.953811 -1.208823  ... -0.332718  0.968807 -1.175800  2.412305   \n",
       "3  0.778487  0.061402  1.235924  ... -0.061234 -1.473064 -0.224096  1.799955   \n",
       "4  0.367364  1.224779 -0.414487  ... -0.001323  1.751990  0.126268 -0.726049   \n",
       "\n",
       "     f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
       "0 -0.999795 -0.902615  0.029085 -1.033815 -2.009790  0.614850  \n",
       "1  0.851902  1.458978 -0.720660  0.223115  0.488134  1.660502  \n",
       "2 -0.817028  1.279866 -1.463948 -0.136485  0.403303  1.414020  \n",
       "3  0.761479 -1.582447 -0.494427 -0.995809  0.479890  1.087704  \n",
       "4  1.225719 -1.972406 -1.207496 -1.483468  1.001844  0.346338  \n",
       "\n",
       "[5 rows x 1201 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['labels']\n",
    "x = df_scaled.drop(columns=['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 1200)\n",
      "(4200,)\n",
      "(1050, 1200)\n",
      "(1050,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state= 42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 30s 204ms/step - loss: 0.1282 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 37s 283ms/step - loss: 0.1129 - lr: 1.0593e-04\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 24s 182ms/step - loss: 0.1062 - lr: 1.1220e-04\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 24s 180ms/step - loss: 0.1033 - lr: 1.1885e-04\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 24s 178ms/step - loss: 0.1021 - lr: 1.2589e-04\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 22s 164ms/step - loss: 0.1016 - lr: 1.3335e-04\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 22s 165ms/step - loss: 0.1012 - lr: 1.4125e-04\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 22s 167ms/step - loss: 0.1010 - lr: 1.4962e-04\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 22s 168ms/step - loss: 0.1007 - lr: 1.5849e-04\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 0.1005 - lr: 1.6788e-04\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 22s 167ms/step - loss: 0.1003 - lr: 1.7783e-04\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 22s 166ms/step - loss: 0.1000 - lr: 1.8836e-04\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 22s 166ms/step - loss: 0.0998 - lr: 1.9953e-04\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 22s 165ms/step - loss: 0.0995 - lr: 2.1135e-04\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 22s 167ms/step - loss: 0.0993 - lr: 2.2387e-04\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 28s 209ms/step - loss: 0.0991 - lr: 2.3714e-04\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 36s 271ms/step - loss: 0.0988 - lr: 2.5119e-04\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 34s 259ms/step - loss: 0.0986 - lr: 2.6607e-04\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 34s 258ms/step - loss: 0.0984 - lr: 2.8184e-04\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 0.0981 - lr: 2.9854e-04\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 38s 284ms/step - loss: 0.0979 - lr: 3.1623e-04\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 23s 177ms/step - loss: 0.0977 - lr: 3.3497e-04\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 22s 166ms/step - loss: 0.0974 - lr: 3.5481e-04\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 22s 166ms/step - loss: 0.0972 - lr: 3.7584e-04\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 22s 165ms/step - loss: 0.0970 - lr: 3.9811e-04\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 23s 177ms/step - loss: 0.0968 - lr: 4.2170e-04\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 37s 285ms/step - loss: 0.0966 - lr: 4.4668e-04\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 35s 262ms/step - loss: 0.0964 - lr: 4.7315e-04\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 34s 259ms/step - loss: 0.0962 - lr: 5.0119e-04\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 41s 312ms/step - loss: 0.0960 - lr: 5.3088e-04\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 39s 295ms/step - loss: 0.0959 - lr: 5.6234e-04\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 35s 267ms/step - loss: 0.0957 - lr: 5.9566e-04\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 30s 230ms/step - loss: 0.0956 - lr: 6.3096e-04\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 31s 237ms/step - loss: 0.0954 - lr: 6.6834e-04\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 36s 273ms/step - loss: 0.0953 - lr: 7.0795e-04\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 31s 235ms/step - loss: 0.0951 - lr: 7.4989e-04\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 38s 289ms/step - loss: 0.0950 - lr: 7.9433e-04\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 41s 307ms/step - loss: 0.0949 - lr: 8.4140e-04\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 33s 251ms/step - loss: 0.0948 - lr: 8.9125e-04\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 35s 265ms/step - loss: 0.0947 - lr: 9.4406e-04\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 36s 271ms/step - loss: 0.0946 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 36s 276ms/step - loss: 0.0945 - lr: 0.0011\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 36s 269ms/step - loss: 0.0944 - lr: 0.0011\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 26s 197ms/step - loss: 0.0943 - lr: 0.0012\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 36s 271ms/step - loss: 0.0942 - lr: 0.0013\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 35s 265ms/step - loss: 0.0941 - lr: 0.0013\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 33s 252ms/step - loss: 0.0941 - lr: 0.0014\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 32s 241ms/step - loss: 0.0939 - lr: 0.0015\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 32s 243ms/step - loss: 0.0938 - lr: 0.0016\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 33s 249ms/step - loss: 0.0938 - lr: 0.0017\n"
     ]
    }
   ],
   "source": [
    "model_tune = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),input_shape=[None]),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-4 * 10**(epoch / 40))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(momentum=0.9)\n",
    "\n",
    "model_tune.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer)\n",
    "\n",
    "history = model_tune.fit(x_train, y_train, epochs=50, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = 1e-4 * (10 ** (np.arange(50) / 40))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid(True)\n",
    "plt.semilogx(lrs, history.history[\"loss\"])\n",
    "plt.tick_params('both', length=10, width=1, which='both')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        if logs.get('val_accuracy') is not None and logs.get('val_accuracy') >= 0.98:                 \n",
    "            print(\"\\nReached 88% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = myCallback()\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),input_shape=[None]),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate= 0.01, momentum=0.9)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.Huber(), \n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "132/132 [==============================] - 29s 199ms/step - loss: 0.0978 - accuracy: 0.7307 - val_loss: 0.0916 - val_accuracy: 0.7429\n",
      "Epoch 2/70\n",
      "132/132 [==============================] - 24s 183ms/step - loss: 0.0944 - accuracy: 0.7279 - val_loss: 0.0912 - val_accuracy: 0.7429\n",
      "Epoch 3/70\n",
      " 31/132 [======>.......................] - ETA: 16s - loss: 0.0939 - accuracy: 0.7218"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs \u001b[39m=\u001b[39;49m \u001b[39m70\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[callbacks], validation_data\u001b[39m=\u001b[39;49m (x_test, y_test))\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\miniconda-py3-tf2.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\miniconda-py3-tf2.0\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\miniconda-py3-tf2.0\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\miniconda-py3-tf2.0\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\miniconda-py3-tf2.0\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\miniconda-py3-tf2.0\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\miniconda-py3-tf2.0\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\miniconda-py3-tf2.0\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\miniconda-py3-tf2.0\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 70, callbacks=[callbacks], validation_data= (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history[\"val_{}\".format(metric)])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, f'val_{metric}'])\n",
    "    plt.show()\n",
    "    \n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
