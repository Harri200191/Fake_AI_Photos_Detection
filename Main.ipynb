{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1190</th>\n",
       "      <th>f_1191</th>\n",
       "      <th>f_1192</th>\n",
       "      <th>f_1193</th>\n",
       "      <th>f_1194</th>\n",
       "      <th>f_1195</th>\n",
       "      <th>f_1196</th>\n",
       "      <th>f_1197</th>\n",
       "      <th>f_1198</th>\n",
       "      <th>f_1199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.033875</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>-0.142131</td>\n",
       "      <td>-0.177117</td>\n",
       "      <td>-1.470684</td>\n",
       "      <td>1.669562</td>\n",
       "      <td>-0.196530</td>\n",
       "      <td>-0.125239</td>\n",
       "      <td>-0.452284</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.111266</td>\n",
       "      <td>0.716084</td>\n",
       "      <td>0.060039</td>\n",
       "      <td>0.301279</td>\n",
       "      <td>-1.174846</td>\n",
       "      <td>-1.076498</td>\n",
       "      <td>-0.069452</td>\n",
       "      <td>-0.604012</td>\n",
       "      <td>-2.179176</td>\n",
       "      <td>0.558003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.348835</td>\n",
       "      <td>0.294815</td>\n",
       "      <td>-0.557577</td>\n",
       "      <td>-2.020773</td>\n",
       "      <td>-1.234715</td>\n",
       "      <td>1.633930</td>\n",
       "      <td>-1.680658</td>\n",
       "      <td>-0.358146</td>\n",
       "      <td>0.166122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735240</td>\n",
       "      <td>0.829781</td>\n",
       "      <td>1.521941</td>\n",
       "      <td>1.347946</td>\n",
       "      <td>0.754505</td>\n",
       "      <td>1.330642</td>\n",
       "      <td>-0.754453</td>\n",
       "      <td>0.582956</td>\n",
       "      <td>0.252671</td>\n",
       "      <td>1.495870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.113248</td>\n",
       "      <td>-0.607726</td>\n",
       "      <td>-0.947791</td>\n",
       "      <td>0.830851</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.498321</td>\n",
       "      <td>-1.493958</td>\n",
       "      <td>0.789572</td>\n",
       "      <td>-1.311018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104698</td>\n",
       "      <td>0.616189</td>\n",
       "      <td>-1.035953</td>\n",
       "      <td>2.111387</td>\n",
       "      <td>-0.984415</td>\n",
       "      <td>1.148076</td>\n",
       "      <td>-1.433554</td>\n",
       "      <td>0.243372</td>\n",
       "      <td>0.170083</td>\n",
       "      <td>1.274795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.223321</td>\n",
       "      <td>-0.479048</td>\n",
       "      <td>-1.925789</td>\n",
       "      <td>1.680377</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>-1.453307</td>\n",
       "      <td>0.605559</td>\n",
       "      <td>-0.019024</td>\n",
       "      <td>1.065448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360237</td>\n",
       "      <td>-1.957863</td>\n",
       "      <td>-0.123384</td>\n",
       "      <td>1.505329</td>\n",
       "      <td>0.660290</td>\n",
       "      <td>-1.769443</td>\n",
       "      <td>-0.547756</td>\n",
       "      <td>-0.568122</td>\n",
       "      <td>0.244645</td>\n",
       "      <td>0.982116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.160109</td>\n",
       "      <td>0.422684</td>\n",
       "      <td>-0.308029</td>\n",
       "      <td>0.227744</td>\n",
       "      <td>0.432854</td>\n",
       "      <td>0.608348</td>\n",
       "      <td>0.193832</td>\n",
       "      <td>1.035091</td>\n",
       "      <td>-0.538868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416629</td>\n",
       "      <td>1.441766</td>\n",
       "      <td>0.212572</td>\n",
       "      <td>-0.994721</td>\n",
       "      <td>1.143999</td>\n",
       "      <td>-2.166923</td>\n",
       "      <td>-1.199248</td>\n",
       "      <td>-1.028636</td>\n",
       "      <td>0.752791</td>\n",
       "      <td>0.317169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels       f_0       f_1       f_2       f_3       f_4       f_5   \n",
       "0       0 -2.033875  0.978446 -0.142131 -0.177117 -1.470684  1.669562  \\\n",
       "1       1 -0.348835  0.294815 -0.557577 -2.020773 -1.234715  1.633930   \n",
       "2       1  0.113248 -0.607726 -0.947791  0.830851  0.998291  0.498321   \n",
       "3       0  1.223321 -0.479048 -1.925789  1.680377  0.021840 -1.453307   \n",
       "4       0  0.160109  0.422684 -0.308029  0.227744  0.432854  0.608348   \n",
       "\n",
       "        f_6       f_7       f_8  ...    f_1190    f_1191    f_1192    f_1193   \n",
       "0 -0.196530 -0.125239 -0.452284  ... -1.111266  0.716084  0.060039  0.301279  \\\n",
       "1 -1.680658 -0.358146  0.166122  ...  0.735240  0.829781  1.521941  1.347946   \n",
       "2 -1.493958  0.789572 -1.311018  ...  0.104698  0.616189 -1.035953  2.111387   \n",
       "3  0.605559 -0.019024  1.065448  ...  0.360237 -1.957863 -0.123384  1.505329   \n",
       "4  0.193832  1.035091 -0.538868  ...  0.416629  1.441766  0.212572 -0.994721   \n",
       "\n",
       "     f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
       "0 -1.174846 -1.076498 -0.069452 -0.604012 -2.179176  0.558003  \n",
       "1  0.754505  1.330642 -0.754453  0.582956  0.252671  1.495870  \n",
       "2 -0.984415  1.148076 -1.433554  0.243372  0.170083  1.274795  \n",
       "3  0.660290 -1.769443 -0.547756 -0.568122  0.244645  0.982116  \n",
       "4  1.143999 -2.166923 -1.199248 -1.028636  0.752791  0.317169  \n",
       "\n",
       "[5 rows x 1201 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels    0\n",
       "f_0       0\n",
       "f_1       0\n",
       "f_2       0\n",
       "f_3       0\n",
       "         ..\n",
       "f_1195    0\n",
       "f_1196    0\n",
       "f_1197    0\n",
       "f_1198    0\n",
       "f_1199    0\n",
       "Length: 1201, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5250, 1201)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep = data[\"labels\"]\n",
    "indep = data.drop(columns=[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1190</th>\n",
       "      <th>f_1191</th>\n",
       "      <th>f_1192</th>\n",
       "      <th>f_1193</th>\n",
       "      <th>f_1194</th>\n",
       "      <th>f_1195</th>\n",
       "      <th>f_1196</th>\n",
       "      <th>f_1197</th>\n",
       "      <th>f_1198</th>\n",
       "      <th>f_1199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.388242</td>\n",
       "      <td>0.868285</td>\n",
       "      <td>-0.427619</td>\n",
       "      <td>-0.678964</td>\n",
       "      <td>-1.625735</td>\n",
       "      <td>0.262761</td>\n",
       "      <td>1.243040</td>\n",
       "      <td>1.537751</td>\n",
       "      <td>-0.352028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.776403</td>\n",
       "      <td>-0.662884</td>\n",
       "      <td>-0.257091</td>\n",
       "      <td>-1.168413</td>\n",
       "      <td>0.223260</td>\n",
       "      <td>-0.482520</td>\n",
       "      <td>-0.085453</td>\n",
       "      <td>-0.382265</td>\n",
       "      <td>-0.539349</td>\n",
       "      <td>-1.682404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.496920</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.989040</td>\n",
       "      <td>0.451422</td>\n",
       "      <td>0.513516</td>\n",
       "      <td>-0.099658</td>\n",
       "      <td>-1.124326</td>\n",
       "      <td>0.729430</td>\n",
       "      <td>-0.216224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379635</td>\n",
       "      <td>-1.760084</td>\n",
       "      <td>1.125450</td>\n",
       "      <td>-0.328047</td>\n",
       "      <td>-0.880305</td>\n",
       "      <td>-1.257607</td>\n",
       "      <td>0.964312</td>\n",
       "      <td>2.021104</td>\n",
       "      <td>0.655021</td>\n",
       "      <td>-0.423029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.128369</td>\n",
       "      <td>-0.537951</td>\n",
       "      <td>2.544358</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>-1.904994</td>\n",
       "      <td>0.776961</td>\n",
       "      <td>-0.495768</td>\n",
       "      <td>0.060111</td>\n",
       "      <td>-1.418468</td>\n",
       "      <td>...</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>-1.373589</td>\n",
       "      <td>-0.483701</td>\n",
       "      <td>-0.964782</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>0.066040</td>\n",
       "      <td>-0.444567</td>\n",
       "      <td>-0.531935</td>\n",
       "      <td>-0.878660</td>\n",
       "      <td>1.099488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.051253</td>\n",
       "      <td>1.746814</td>\n",
       "      <td>0.681177</td>\n",
       "      <td>1.844524</td>\n",
       "      <td>-0.327977</td>\n",
       "      <td>1.226839</td>\n",
       "      <td>-0.085519</td>\n",
       "      <td>0.379008</td>\n",
       "      <td>-1.003667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442288</td>\n",
       "      <td>-2.794472</td>\n",
       "      <td>-0.763468</td>\n",
       "      <td>-0.789832</td>\n",
       "      <td>-0.113209</td>\n",
       "      <td>-2.703150</td>\n",
       "      <td>-2.058728</td>\n",
       "      <td>1.070627</td>\n",
       "      <td>-0.458045</td>\n",
       "      <td>-0.435825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.423209</td>\n",
       "      <td>-0.983594</td>\n",
       "      <td>-1.694170</td>\n",
       "      <td>1.197507</td>\n",
       "      <td>1.044211</td>\n",
       "      <td>0.518777</td>\n",
       "      <td>-0.298612</td>\n",
       "      <td>-0.365174</td>\n",
       "      <td>0.738447</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.624450</td>\n",
       "      <td>-3.200223</td>\n",
       "      <td>0.711422</td>\n",
       "      <td>-0.190394</td>\n",
       "      <td>0.337224</td>\n",
       "      <td>-1.656639</td>\n",
       "      <td>0.707360</td>\n",
       "      <td>-0.562290</td>\n",
       "      <td>1.471181</td>\n",
       "      <td>-0.192000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       f_0       f_1       f_2       f_3       f_4       f_5       f_6   \n",
       "0   1 -3.388242  0.868285 -0.427619 -0.678964 -1.625735  0.262761  1.243040  \\\n",
       "1   2 -0.496920  0.952381  0.989040  0.451422  0.513516 -0.099658 -1.124326   \n",
       "2   3  1.128369 -0.537951  2.544358  1.165254 -1.904994  0.776961 -0.495768   \n",
       "3   4  0.051253  1.746814  0.681177  1.844524 -0.327977  1.226839 -0.085519   \n",
       "4   5  1.423209 -0.983594 -1.694170  1.197507  1.044211  0.518777 -0.298612   \n",
       "\n",
       "        f_7       f_8  ...    f_1190    f_1191    f_1192    f_1193    f_1194   \n",
       "0  1.537751 -0.352028  ... -0.776403 -0.662884 -0.257091 -1.168413  0.223260  \\\n",
       "1  0.729430 -0.216224  ...  0.379635 -1.760084  1.125450 -0.328047 -0.880305   \n",
       "2  0.060111 -1.418468  ...  1.165254 -1.373589 -0.483701 -0.964782 -0.869555   \n",
       "3  0.379008 -1.003667  ... -0.442288 -2.794472 -0.763468 -0.789832 -0.113209   \n",
       "4 -0.365174  0.738447  ... -2.624450 -3.200223  0.711422 -0.190394  0.337224   \n",
       "\n",
       "     f_1195    f_1196    f_1197    f_1198    f_1199  \n",
       "0 -0.482520 -0.085453 -0.382265 -0.539349 -1.682404  \n",
       "1 -1.257607  0.964312  2.021104  0.655021 -0.423029  \n",
       "2  0.066040 -0.444567 -0.531935 -0.878660  1.099488  \n",
       "3 -2.703150 -2.058728  1.070627 -0.458045 -0.435825  \n",
       "4 -1.656639  0.707360 -0.562290  1.471181 -0.192000  \n",
       "\n",
       "[5 rows x 1201 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(columns=[\"id\"], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "2245    1\n",
       "2246    0\n",
       "2247    0\n",
       "2248    0\n",
       "2249    1\n",
       "Name: labels, Length: 2250, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_data = pd.read_csv(\"solution_format.csv\")\n",
    "temp_data.head()\n",
    "label_col = temp_data[\"labels\"]\n",
    "label_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.insert(0,'labels', label_col )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1190</th>\n",
       "      <th>f_1191</th>\n",
       "      <th>f_1192</th>\n",
       "      <th>f_1193</th>\n",
       "      <th>f_1194</th>\n",
       "      <th>f_1195</th>\n",
       "      <th>f_1196</th>\n",
       "      <th>f_1197</th>\n",
       "      <th>f_1198</th>\n",
       "      <th>f_1199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.388242</td>\n",
       "      <td>0.868285</td>\n",
       "      <td>-0.427619</td>\n",
       "      <td>-0.678964</td>\n",
       "      <td>-1.625735</td>\n",
       "      <td>0.262761</td>\n",
       "      <td>1.243040</td>\n",
       "      <td>1.537751</td>\n",
       "      <td>-0.352028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.776403</td>\n",
       "      <td>-0.662884</td>\n",
       "      <td>-0.257091</td>\n",
       "      <td>-1.168413</td>\n",
       "      <td>0.223260</td>\n",
       "      <td>-0.482520</td>\n",
       "      <td>-0.085453</td>\n",
       "      <td>-0.382265</td>\n",
       "      <td>-0.539349</td>\n",
       "      <td>-1.682404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.496920</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.989040</td>\n",
       "      <td>0.451422</td>\n",
       "      <td>0.513516</td>\n",
       "      <td>-0.099658</td>\n",
       "      <td>-1.124326</td>\n",
       "      <td>0.729430</td>\n",
       "      <td>-0.216224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379635</td>\n",
       "      <td>-1.760084</td>\n",
       "      <td>1.125450</td>\n",
       "      <td>-0.328047</td>\n",
       "      <td>-0.880305</td>\n",
       "      <td>-1.257607</td>\n",
       "      <td>0.964312</td>\n",
       "      <td>2.021104</td>\n",
       "      <td>0.655021</td>\n",
       "      <td>-0.423029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.128369</td>\n",
       "      <td>-0.537951</td>\n",
       "      <td>2.544358</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>-1.904994</td>\n",
       "      <td>0.776961</td>\n",
       "      <td>-0.495768</td>\n",
       "      <td>0.060111</td>\n",
       "      <td>-1.418468</td>\n",
       "      <td>...</td>\n",
       "      <td>1.165254</td>\n",
       "      <td>-1.373589</td>\n",
       "      <td>-0.483701</td>\n",
       "      <td>-0.964782</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>0.066040</td>\n",
       "      <td>-0.444567</td>\n",
       "      <td>-0.531935</td>\n",
       "      <td>-0.878660</td>\n",
       "      <td>1.099488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.051253</td>\n",
       "      <td>1.746814</td>\n",
       "      <td>0.681177</td>\n",
       "      <td>1.844524</td>\n",
       "      <td>-0.327977</td>\n",
       "      <td>1.226839</td>\n",
       "      <td>-0.085519</td>\n",
       "      <td>0.379008</td>\n",
       "      <td>-1.003667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442288</td>\n",
       "      <td>-2.794472</td>\n",
       "      <td>-0.763468</td>\n",
       "      <td>-0.789832</td>\n",
       "      <td>-0.113209</td>\n",
       "      <td>-2.703150</td>\n",
       "      <td>-2.058728</td>\n",
       "      <td>1.070627</td>\n",
       "      <td>-0.458045</td>\n",
       "      <td>-0.435825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.423209</td>\n",
       "      <td>-0.983594</td>\n",
       "      <td>-1.694170</td>\n",
       "      <td>1.197507</td>\n",
       "      <td>1.044211</td>\n",
       "      <td>0.518777</td>\n",
       "      <td>-0.298612</td>\n",
       "      <td>-0.365174</td>\n",
       "      <td>0.738447</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.624450</td>\n",
       "      <td>-3.200223</td>\n",
       "      <td>0.711422</td>\n",
       "      <td>-0.190394</td>\n",
       "      <td>0.337224</td>\n",
       "      <td>-1.656639</td>\n",
       "      <td>0.707360</td>\n",
       "      <td>-0.562290</td>\n",
       "      <td>1.471181</td>\n",
       "      <td>-0.192000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels       f_0       f_1       f_2       f_3       f_4       f_5   \n",
       "0       0 -3.388242  0.868285 -0.427619 -0.678964 -1.625735  0.262761  \\\n",
       "1       1 -0.496920  0.952381  0.989040  0.451422  0.513516 -0.099658   \n",
       "2       0  1.128369 -0.537951  2.544358  1.165254 -1.904994  0.776961   \n",
       "3       1  0.051253  1.746814  0.681177  1.844524 -0.327977  1.226839   \n",
       "4       0  1.423209 -0.983594 -1.694170  1.197507  1.044211  0.518777   \n",
       "\n",
       "        f_6       f_7       f_8  ...    f_1190    f_1191    f_1192    f_1193   \n",
       "0  1.243040  1.537751 -0.352028  ... -0.776403 -0.662884 -0.257091 -1.168413  \\\n",
       "1 -1.124326  0.729430 -0.216224  ...  0.379635 -1.760084  1.125450 -0.328047   \n",
       "2 -0.495768  0.060111 -1.418468  ...  1.165254 -1.373589 -0.483701 -0.964782   \n",
       "3 -0.085519  0.379008 -1.003667  ... -0.442288 -2.794472 -0.763468 -0.789832   \n",
       "4 -0.298612 -0.365174  0.738447  ... -2.624450 -3.200223  0.711422 -0.190394   \n",
       "\n",
       "     f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
       "0  0.223260 -0.482520 -0.085453 -0.382265 -0.539349 -1.682404  \n",
       "1 -0.880305 -1.257607  0.964312  2.021104  0.655021 -0.423029  \n",
       "2 -0.869555  0.066040 -0.444567 -0.531935 -0.878660  1.099488  \n",
       "3 -0.113209 -2.703150 -2.058728  1.070627 -0.458045 -0.435825  \n",
       "4  0.337224 -1.656639  0.707360 -0.562290  1.471181 -0.192000  \n",
       "\n",
       "[5 rows x 1201 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dep = test_data[\"labels\"]\n",
    "test_indep = test_data.drop(columns=[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        if logs.get('validation_accuracy') is not None and logs.get('validation_accuracy') > 0.998:                 \n",
    "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.3373 - accuracy: 0.8427 - val_loss: 3.0512 - val_accuracy: 0.4942\n",
      "Epoch 2/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.1196 - accuracy: 0.9558 - val_loss: 4.7001 - val_accuracy: 0.4991\n",
      "Epoch 3/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.0328 - accuracy: 0.9886 - val_loss: 9.3858 - val_accuracy: 0.4942\n",
      "Epoch 4/50\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 0.0166 - accuracy: 0.9964 - val_loss: 8.6710 - val_accuracy: 0.4996\n",
      "Epoch 5/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.0325 - accuracy: 0.9895 - val_loss: 6.4507 - val_accuracy: 0.4991\n",
      "Epoch 6/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.0248 - accuracy: 0.9916 - val_loss: 7.2298 - val_accuracy: 0.5027\n",
      "Epoch 7/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 10.2033 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 9.8602 - val_accuracy: 0.4982\n",
      "Epoch 9/50\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 10.6916 - val_accuracy: 0.4987\n",
      "Epoch 10/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 11.8545 - val_accuracy: 0.4969\n",
      "Epoch 11/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 7.5069e-04 - accuracy: 0.9998 - val_loss: 12.9224 - val_accuracy: 0.4978\n",
      "Epoch 12/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 8.1139e-05 - accuracy: 1.0000 - val_loss: 13.2028 - val_accuracy: 0.4964\n",
      "Epoch 13/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 4.5591e-05 - accuracy: 1.0000 - val_loss: 13.4920 - val_accuracy: 0.4973\n",
      "Epoch 14/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 3.3279e-05 - accuracy: 1.0000 - val_loss: 13.7317 - val_accuracy: 0.4982\n",
      "Epoch 15/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 2.6155e-05 - accuracy: 1.0000 - val_loss: 13.9537 - val_accuracy: 0.4978\n",
      "Epoch 16/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 2.1212e-05 - accuracy: 1.0000 - val_loss: 14.1509 - val_accuracy: 0.4982\n",
      "Epoch 17/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 1.7576e-05 - accuracy: 1.0000 - val_loss: 14.3349 - val_accuracy: 0.4987\n",
      "Epoch 18/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 1.4796e-05 - accuracy: 1.0000 - val_loss: 14.5024 - val_accuracy: 0.4987\n",
      "Epoch 19/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 1.2553e-05 - accuracy: 1.0000 - val_loss: 14.6637 - val_accuracy: 0.4991\n",
      "Epoch 20/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 1.0796e-05 - accuracy: 1.0000 - val_loss: 14.8151 - val_accuracy: 0.5000\n",
      "Epoch 21/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 9.3547e-06 - accuracy: 1.0000 - val_loss: 14.9579 - val_accuracy: 0.5000\n",
      "Epoch 22/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 8.1558e-06 - accuracy: 1.0000 - val_loss: 15.1003 - val_accuracy: 0.5000\n",
      "Epoch 23/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 7.1342e-06 - accuracy: 1.0000 - val_loss: 15.2365 - val_accuracy: 0.5000\n",
      "Epoch 24/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 6.2739e-06 - accuracy: 1.0000 - val_loss: 15.3703 - val_accuracy: 0.5000\n",
      "Epoch 25/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 5.5315e-06 - accuracy: 1.0000 - val_loss: 15.4951 - val_accuracy: 0.4996\n",
      "Epoch 26/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 4.8990e-06 - accuracy: 1.0000 - val_loss: 15.6197 - val_accuracy: 0.4991\n",
      "Epoch 27/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 4.3476e-06 - accuracy: 1.0000 - val_loss: 15.7457 - val_accuracy: 0.4991\n",
      "Epoch 28/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 3.8720e-06 - accuracy: 1.0000 - val_loss: 15.8664 - val_accuracy: 0.4987\n",
      "Epoch 29/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 3.4522e-06 - accuracy: 1.0000 - val_loss: 15.9852 - val_accuracy: 0.4987\n",
      "Epoch 30/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 3.0774e-06 - accuracy: 1.0000 - val_loss: 16.1043 - val_accuracy: 0.4987\n",
      "Epoch 31/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 2.7548e-06 - accuracy: 1.0000 - val_loss: 16.2164 - val_accuracy: 0.4987\n",
      "Epoch 32/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 2.4728e-06 - accuracy: 1.0000 - val_loss: 16.3315 - val_accuracy: 0.4987\n",
      "Epoch 33/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 2.2197e-06 - accuracy: 1.0000 - val_loss: 16.4449 - val_accuracy: 0.4987\n",
      "Epoch 34/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 1.9947e-06 - accuracy: 1.0000 - val_loss: 16.5574 - val_accuracy: 0.4987\n",
      "Epoch 35/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 1.7960e-06 - accuracy: 1.0000 - val_loss: 16.6703 - val_accuracy: 0.4987\n",
      "Epoch 36/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 1.6097e-06 - accuracy: 1.0000 - val_loss: 16.7871 - val_accuracy: 0.4987\n",
      "Epoch 37/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 1.4515e-06 - accuracy: 1.0000 - val_loss: 16.8988 - val_accuracy: 0.4991\n",
      "Epoch 38/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 1.3104e-06 - accuracy: 1.0000 - val_loss: 17.0047 - val_accuracy: 0.4991\n",
      "Epoch 39/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 1.1851e-06 - accuracy: 1.0000 - val_loss: 17.1071 - val_accuracy: 0.4987\n",
      "Epoch 40/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 1.0723e-06 - accuracy: 1.0000 - val_loss: 17.2116 - val_accuracy: 0.4987\n",
      "Epoch 41/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 9.6892e-07 - accuracy: 1.0000 - val_loss: 17.3228 - val_accuracy: 0.4987\n",
      "Epoch 42/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 8.7776e-07 - accuracy: 1.0000 - val_loss: 17.4240 - val_accuracy: 0.4991\n",
      "Epoch 43/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 7.9586e-07 - accuracy: 1.0000 - val_loss: 17.5262 - val_accuracy: 0.4991\n",
      "Epoch 44/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 7.2087e-07 - accuracy: 1.0000 - val_loss: 17.6299 - val_accuracy: 0.4991\n",
      "Epoch 45/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 6.5441e-07 - accuracy: 1.0000 - val_loss: 17.7343 - val_accuracy: 0.4991\n",
      "Epoch 46/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 5.9388e-07 - accuracy: 1.0000 - val_loss: 17.8339 - val_accuracy: 0.4991\n",
      "Epoch 47/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 5.3951e-07 - accuracy: 1.0000 - val_loss: 17.9386 - val_accuracy: 0.4987\n",
      "Epoch 48/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 4.8988e-07 - accuracy: 1.0000 - val_loss: 18.0356 - val_accuracy: 0.4987\n",
      "Epoch 49/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 4.4515e-07 - accuracy: 1.0000 - val_loss: 18.1403 - val_accuracy: 0.4987\n",
      "Epoch 50/50\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 4.0439e-07 - accuracy: 1.0000 - val_loss: 18.2399 - val_accuracy: 0.4987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181d9c83640>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = myCallback()\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units = 264, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(units = 128, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(units = 64, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(units = 32, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(units = 1, activation = 'sigmoid'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "loss= \"binary_crossentropy\", \n",
    "metrics=['accuracy'])\n",
    "\n",
    "model.fit(indep, dep, epochs=50, callbacks=[callbacks], validation_data=(test_indep, test_dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
